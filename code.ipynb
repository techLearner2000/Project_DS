{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import scale "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/minyan/Documents/stats780/Project_DS/csgo_round_snapshots.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['round_winner'] = df['round_winner'].apply(lambda x: 1 if x == 'CT' else 0)\n",
    "print(df['round_winner'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='round_winner', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bomb_planted'] = df['bomb_planted'].astype(int)\n",
    "n = 10\n",
    "df_selected = df.iloc[:, list(range(n)) + [-1]]\n",
    "df_selected = df_selected.drop('map', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "df_selected = df.iloc[:, list(range(n)) + [-1]]\n",
    "df_selected = df_selected.drop('map', axis=1)\n",
    "\n",
    "X = df_selected.drop(['round_winner', 'bomb_planted'], axis=1)\n",
    "Y = df_selected['round_winner']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "std.fit(X)\n",
    "X = pd.DataFrame(std.transform(X), columns=X.columns)\n",
    "X['bomb_planted'] = df_selected['bomb_planted']\n",
    "X.info()\n",
    "#X_pca = pd.DataFrame(scale(df_selected), index=df_selected.index, columns=df_selected.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=8964)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_X = PCA()\n",
    "\n",
    "X_pca = pd.DataFrame(pca_X.fit_transform(X), columns=X.columns, index=X.index)\n",
    "X_pca\n",
    "\n",
    "#Train/test for decision trees\n",
    "X_train_p, X_test_p, Y_train_p, Y_test_p = train_test_split(X_pca, Y, test_size=0.3, random_state=8964)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree=DecisionTreeClassifier(max_depth=16, min_samples_split=80, random_state=8964)\n",
    "tree.fit(X_train_p,Y_train_p)\n",
    "\n",
    "# predictions=tree.predict(X_train)\n",
    "# print(accuracy_score(Y_train,predictions)) # clearly overfitting\n",
    "\n",
    "predictions=tree.predict(X_test_p)\n",
    "tree_score=accuracy_score(Y_test_p,predictions)\n",
    "tree_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=8964)  # For classification\n",
    "rf.fit(X_train_p, Y_train_p)\n",
    "Y_pred = rf.predict(X_test_p)\n",
    "\n",
    "# For classification\n",
    "accuracy = accuracy_score(Y_test_p, Y_pred)\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Set model parameters\n",
    "n_layers = 4\n",
    "n_nodes = 300\n",
    "regularized = False\n",
    "dropout = True\n",
    "epochs = 20\n",
    "\n",
    "# Make a Keras DNN model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for n in range(n_layers):\n",
    "    if regularized:\n",
    "        model.add(keras.layers.Dense(n_nodes, kernel_initializer=\"he_normal\",\n",
    "         kernel_regularizer=keras.regularizers.l1(0.01), use_bias=False))\n",
    "    else:\n",
    "        model.add(keras.layers.Dense(n_nodes,\n",
    "         kernel_initializer=\"he_normal\", use_bias=False))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"elu\"))\n",
    "    if dropout:\n",
    "        model.add(keras.layers.Dropout(rate=0.2))\n",
    "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "\n",
    "# Make a callback that reduces LR on plateau\n",
    "reduce_lr_cb = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                                 patience=5, min_lr=0.001)\n",
    "\n",
    "# Make a callback for early stopping\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5)\n",
    "\n",
    "# Train DNN.\n",
    "history = model.fit(np.array(X_train), np.array(Y_train), epochs=epochs,\n",
    "     validation_data=(np.array(X_test), np.array(Y_test)),\n",
    "      callbacks=[reduce_lr_cb, early_stopping_cb], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats780f23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
